{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT0FBE3PPRLz"
   },
   "source": [
    "# Experimentation âš› ðŸ§ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BI2N-o-XKJH"
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"torch>=1.2.0,<2.0.0\" \n",
    "! pip install --quiet -U matplotlib==3.1.3 pyyaml==5.4.1 \"plotly>=5.9.0,<6.0.0\" \"seaborn>=0.11.2,<1.0.0\"\n",
    "! pip install --quiet -U \"mlfoundry>=0.3.33,<0.5.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdt8gVseYCy3"
   },
   "source": [
    "## Login and initialize MlFoundry client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fG1rfFxUX-36"
   },
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upbdntWEYu3J"
   },
   "source": [
    "## Fashion MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-1fzLe5W5F2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from types import SimpleNamespace\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaCuLytLNkoR"
   },
   "source": [
    "## Start a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEc96M5EVItB",
    "outputId": "266e6143-6513-4173-e338-764351d393ce"
   },
   "outputs": [],
   "source": [
    "run = client.create_run(project_name=\"fashion-mnist-demo-trial\", run_name=\"pytorch-cnn\")\n",
    "run.set_tags({\"framework\": \"pytorch\", \"model-type\": \"cnn\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulThWq05cPOf"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGYJbA42cF03"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.FashionMNIST('../fashion-mnist-data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST('../fashion-mnist-data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXIN1wztajsO"
   },
   "outputs": [],
   "source": [
    "! mkdir -p ../fashion-mnist-data/FashionMNIST/gz/\n",
    "! cp ../fashion-mnist-data/FashionMNIST/raw/*.gz ../fashion-mnist-data/FashionMNIST/gz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbk8AGP5NwJO"
   },
   "source": [
    "## Log the raw dataset as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmsEgN9YVHyc"
   },
   "outputs": [],
   "source": [
    "# Log dataset folder as artifact\n",
    "run.log_artifact(\"../fashion-mnist-data/FashionMNIST/gz/\", artifact_path=\"fashion-mnist-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eihhuKchcTyM"
   },
   "outputs": [],
   "source": [
    "idx2label = [\n",
    "  \"T-shirt/Top\",\n",
    "  \"Trouser\",\n",
    "  \"Pullover\",\n",
    "  \"Dress\",\n",
    "  \"Coat\", \n",
    "  \"Sandal\", \n",
    "  \"Shirt\",\n",
    "  \"Sneaker\",\n",
    "  \"Bag\",\n",
    "  \"Ankle Boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU_BreptN3Ol"
   },
   "source": [
    "## Log the label map as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKw-WBNYVkLE"
   },
   "outputs": [],
   "source": [
    "# Log labels as artifact\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump({\"idx2label\": idx2label}, f)\n",
    "run.log_artifact(\"config.json\", artifact_path=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZPQjY8AN972"
   },
   "source": [
    "## A look at a sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0id33Xzn4ZK"
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame([y for _, y in train_dataset], columns=[\"y\"])\n",
    "y_test = pd.DataFrame([y for _, y in test_dataset], columns=[\"y\"])\n",
    "train_sample = y_train.groupby('y').sample(n=3, random_state=42).index\n",
    "test_sample = y_test.groupby('y').sample(n=3, random_state=42).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjKuM_HlhZZG"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 10))\n",
    "for i, idx in enumerate(train_sample):\n",
    "    image_t, label_idx = train_dataset[idx]\n",
    "    ax = fig.add_subplot(5, 50 // 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(image_t), cmap='gray')\n",
    "    ax.set_title(idx2label[label_idx])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAY3f7HQcQP_"
   },
   "source": [
    "## Define the CNN Model and training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TApZ1lwRZyOa"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3FJLGAsZ4WL"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value: int):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def make_dataloader(dataset, batch_size, pin_memory=False, shuffle=False):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=1,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_y(model, device, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss = 0\n",
    "    for (batch_input, batch_target) in tqdm(dataloader, total=len(dataloader), desc=\"get_y\", disable=True):\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "        predicted = model(batch_input)\n",
    "        loss += F.nll_loss(predicted, batch_target, reduction='sum').item()  # sum up batch loss\n",
    "        # get the index of the max log-probability\n",
    "        _y_true = batch_target.cpu().numpy()\n",
    "        _y_pred = predicted.argmax(dim=1).detach().cpu().numpy()\n",
    "        y_true.append(_y_true)\n",
    "        y_pred.append(_y_pred)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return loss, y_true, y_pred\n",
    "\n",
    "\n",
    "def get_eval_metrics(y_true, y_pred):\n",
    "    return {\n",
    "      'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred),\n",
    "      'f1': f1_score(y_true=y_true, y_pred=y_pred, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred, prefix, loss=None):\n",
    "    metrics_to_log = {}\n",
    "    if loss is not None:\n",
    "        metrics_to_log[f\"{prefix}/loss\"] = loss\n",
    "    metrics = get_eval_metrics(y_true=y_true, y_pred=y_pred)\n",
    "    for k, v in metrics.items():\n",
    "        metrics_to_log[f'{prefix}/{k}'] = v\n",
    "    return metrics_to_log\n",
    "\n",
    "\n",
    "def get_plots(y_true, y_pred, labels=None):\n",
    "    plt.clf()\n",
    "    report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
    "    ax = sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)\n",
    "    ax.figure.tight_layout()\n",
    "    report_fig = plt.gcf()\n",
    "    plt.show()\n",
    "    z = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    cm_fig = px.imshow(\n",
    "        z,\n",
    "        text_auto=True,\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Productivity\"),\n",
    "        x=labels,\n",
    "        y=labels,\n",
    "        width=600,\n",
    "        height=600\n",
    "    )\n",
    "    cm_fig.show()\n",
    "    return report_fig, cm_fig\n",
    "\n",
    "\n",
    "  \n",
    "def get_images(dataset, sample, model, device, prefix):\n",
    "    images = {}\n",
    "    dataset = Subset(dataset, sample)\n",
    "    _, y_true, y_pred = get_y(model=model, device=device, dataloader=make_dataloader(dataset, batch_size=1000))\n",
    "    for sample_no, (image_t, _), actual_idx, prediction_idx  in zip(sample, dataset, y_true, y_pred):\n",
    "        images[f\"{prefix}_{sample_no}\"] = mlf.Image(\n",
    "            data_or_path=image_t.squeeze().numpy(),\n",
    "            caption=f\"{prefix}_{sample_no}\",\n",
    "            class_groups={\"actuals\": idx2label[actual_idx], \"predictions\": idx2label[prediction_idx]}\n",
    "        )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnfRg5u7ONeh"
   },
   "source": [
    "## Log training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiOfHT0za6rL",
    "outputId": "a70dd40d-d06b-4a78-b963-5dc5d0fe2f9e"
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    batch_size=64,\n",
    "    test_batch_size=1000,\n",
    "    epochs=1,\n",
    "    lr=1.0,\n",
    "    gamma=0.7,\n",
    "    no_cuda=False,\n",
    "    seed=1,\n",
    "    log_interval=100,\n",
    "    save_model=True\n",
    ")\n",
    "\n",
    "run.log_params(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z0xtrR3OTk4"
   },
   "source": [
    "## Initialize Model, DataLoaders, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzKFGpoWpRTJ"
   },
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "num_classes = len(idx2label)\n",
    "set_random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c5QtELh5Fox"
   },
   "outputs": [],
   "source": [
    "# Make train and test dataloaders\n",
    "train_dataloader = make_dataloader(\n",
    "      train_dataset,\n",
    "      batch_size=args.batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=True\n",
    ")\n",
    "train_dataloader_for_eval = make_dataloader(\n",
    "      train_dataset,\n",
    "      batch_size=args.test_batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=False\n",
    ")\n",
    "test_dataloader = make_dataloader(\n",
    "      test_dataset,\n",
    "      batch_size=args.test_batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPFIt0QY5HNt"
   },
   "outputs": [],
   "source": [
    "# Initialize model and loss\n",
    "model = Net(num_classes=num_classes)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TyFmJLL5KVH"
   },
   "outputs": [],
   "source": [
    "total_steps = args.epochs * len(train_dataloader)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "model = model.to(device)\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0glXr8-QOevu"
   },
   "source": [
    "## The Training loop\n",
    "## Here we will log metrics, plots and sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFscP9dS5NYu"
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, args.epochs + 1), desc=\"epochs\"):\n",
    "    epoch_start_time = timer()\n",
    "    epoch_loss = torch.tensor(0.0).to(device)\n",
    "    for _step, (batch_input, batch_target) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"steps\"):\n",
    "        model.train()\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "        batch_predicted = model(batch_input)\n",
    "        loss = criterion(batch_predicted, batch_target)        \n",
    "        \n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step % args.log_interval == 0:\n",
    "            #################### Logging Metrics ###############################\n",
    "            step_metrics = {\n",
    "                'step/lr': scheduler.get_last_lr()[0],\n",
    "                'train/step/loss': loss.item(),\n",
    "            }\n",
    "            _, y_true_train, y_pred_train = get_y(model, device, train_dataloader_for_eval)\n",
    "            step_metrics.update(get_metrics(y_true_train, y_pred_train, prefix=\"train/step\"))\n",
    "            test_loss, y_true_test, y_pred_test = get_y(model, device, test_dataloader)\n",
    "            step_metrics.update(get_metrics(y_true_test, y_pred_test, prefix=\"test/step\", loss=test_loss))\n",
    "\n",
    "            print(f'epoch={epoch} step={global_step}', step_metrics)\n",
    "            run.log_metrics(step_metrics, step=global_step)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ###################### Logging Metrics #####################################\n",
    "    epoch_loss = epoch_loss.item() / len(train_dataloader)\n",
    "    epoch_time = timer() - epoch_start_time\n",
    "    epoch_metrics = {\n",
    "        'epoch/epoch': epoch,\n",
    "        'epoch/lr': scheduler.get_last_lr()[0],\n",
    "        'train/epoch/loss': epoch_loss,\n",
    "        'epoch/time': epoch_time\n",
    "    }\n",
    "    _, y_true_train, y_pred_train = get_y(model, device, train_dataloader_for_eval)\n",
    "    epoch_metrics.update(get_metrics(y_true_train, y_pred_train, prefix=\"train/epoch\"))\n",
    "    test_loss, y_true_test, y_pred_test = get_y(model, device, test_dataloader)\n",
    "    epoch_metrics.update(get_metrics(y_true_test, y_pred_test, prefix=\"test/epoch\", loss=test_loss))\n",
    "    print(f'epoch={epoch} step={global_step}', epoch_metrics)\n",
    "\n",
    "    run.log_metrics(epoch_metrics, step=global_step)\n",
    "\n",
    "\n",
    "    ###################### Logging Plots #######################################\n",
    "    train_report_plt, train_cm_plt = get_plots(y_true=y_true_train, y_pred=y_pred_train, labels=idx2label)\n",
    "    test_report_plt, test_cm_plt = get_plots(y_true=y_true_test, y_pred=y_pred_test, labels=idx2label)\n",
    "    plots = {\n",
    "        'train_report': train_report_plt,\n",
    "        'train_confusion_matrix': train_cm_plt,\n",
    "        'test_report': test_report_plt,\n",
    "        'test_confusion_matrix': test_cm_plt,\n",
    "    }\n",
    "\n",
    "    run.log_plots(plots, step=global_step)\n",
    "    \n",
    "\n",
    "    ###################### Logging Images ######################################\n",
    "    train_images = get_images(dataset=train_dataset, sample=train_sample, model=model, device=device, prefix=\"train\")\n",
    "    test_images = get_images(dataset=test_dataset, sample=test_sample, model=model, device=device, prefix=\"test\")\n",
    "    images = {**train_images, **test_images}\n",
    "\n",
    "    run.log_images(images, step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOpe0pf6QS8o"
   },
   "source": [
    "## Log the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX7IQ1kvQT29"
   },
   "outputs": [],
   "source": [
    "if args.save_model:\n",
    "    model = model.to(torch.device(\"cpu\"))\n",
    "    run.log_model(name=\"fashion-mnist-pytorch\", model=model, framework=\"pytorch\", description=\"trained on fashion mnist\")\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29dLGTCnO4Tq"
   },
   "source": [
    "# Log dataset stats with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d44yh7sP8MgZ"
   },
   "outputs": [],
   "source": [
    "columns = [f\"pix_{i}_{j}\" for i in range(28) for j in range(28)]\n",
    "train_dataloader = make_dataloader(train_dataset, batch_size=len(train_dataset))\n",
    "test_dataloader = make_dataloader(test_dataset, batch_size=len(test_dataset))\n",
    "X_train, _ = next(iter(train_dataloader))\n",
    "X_test, _ = next(iter(test_dataloader))\n",
    "X_train = pd.DataFrame(X_train.reshape(len(X_train), -1).numpy(), columns=columns)\n",
    "X_test = pd.DataFrame(X_test.reshape(len(X_test), -1).numpy(), columns=columns)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3mY8_lK_Nnn"
   },
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='train',\n",
    "    features=X_train[:500],\n",
    "    predictions=y_pred_train[:500],\n",
    "    actuals=y_true_train[:500],\n",
    "    only_stats=True,\n",
    ")\n",
    "\n",
    "run.log_dataset(\n",
    "    dataset_name='test',\n",
    "    features=X_test[:500],\n",
    "    predictions=y_pred_test[:500],\n",
    "    actuals=y_true_test[:500],\n",
    "    only_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kekmdY2HPCrt"
   },
   "source": [
    "## End the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZRWEjOmCcnV"
   },
   "outputs": [],
   "source": [
    "run.end()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "yT0FBE3PPRLz",
    "7KXuzT7KPFso",
    "lTigA6ZR8WRw",
    "hJrY7uez8alR",
    "aRdcq87t8QXm"
   ],
   "name": "train_and_deploy.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
