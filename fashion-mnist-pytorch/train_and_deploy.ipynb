{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT0FBE3PPRLz"
   },
   "source": [
    "# Experimentation âš› ðŸ§ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BI2N-o-XKJH"
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"torch>=1.2.0,<2.0.0\" \n",
    "! pip install --quiet -U matplotlib==3.1.3 pyyaml==5.4.1 \"plotly>=5.9.0,<6.0.0\" \"seaborn>=0.11.2,<1.0.0\"\n",
    "! pip install --quiet -U \"mlfoundry>=0.3.33,<0.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdt8gVseYCy3"
   },
   "source": [
    "## Login and initialize MlFoundry client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fG1rfFxUX-36"
   },
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "client = mlf.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upbdntWEYu3J"
   },
   "source": [
    "## Fashion MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-1fzLe5W5F2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from types import SimpleNamespace\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, RandomSampler, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaCuLytLNkoR"
   },
   "source": [
    "## Start a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEc96M5EVItB",
    "outputId": "266e6143-6513-4173-e338-764351d393ce"
   },
   "outputs": [],
   "source": [
    "run = client.create_run(project_name=\"fashion-mnist-demo-trial\", run_name=\"pytorch-cnn\")\n",
    "run.set_tags({\"framework\": \"pytorch\", \"model-type\": \"cnn\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulThWq05cPOf"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGYJbA42cF03"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.FashionMNIST('../fashion-mnist-data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST('../fashion-mnist-data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXIN1wztajsO"
   },
   "outputs": [],
   "source": [
    "! mkdir -p ../fashion-mnist-data/FashionMNIST/gz/\n",
    "! cp ../fashion-mnist-data/FashionMNIST/raw/*.gz ../fashion-mnist-data/FashionMNIST/gz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbk8AGP5NwJO"
   },
   "source": [
    "## Log the raw dataset as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmsEgN9YVHyc"
   },
   "outputs": [],
   "source": [
    "# Log dataset folder as artifact\n",
    "run.log_artifact(\"../fashion-mnist-data/FashionMNIST/gz/\", artifact_path=\"fashion-mnist-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eihhuKchcTyM"
   },
   "outputs": [],
   "source": [
    "idx2label = [\n",
    "  \"T-shirt/Top\",\n",
    "  \"Trouser\",\n",
    "  \"Pullover\",\n",
    "  \"Dress\",\n",
    "  \"Coat\", \n",
    "  \"Sandal\", \n",
    "  \"Shirt\",\n",
    "  \"Sneaker\",\n",
    "  \"Bag\",\n",
    "  \"Ankle Boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU_BreptN3Ol"
   },
   "source": [
    "## Log the label map as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKw-WBNYVkLE"
   },
   "outputs": [],
   "source": [
    "# Log labels as artifact\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump({\"idx2label\": idx2label}, f)\n",
    "run.log_artifact(\"config.json\", artifact_path=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZPQjY8AN972"
   },
   "source": [
    "## A look at a sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0id33Xzn4ZK"
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame([y for _, y in train_dataset], columns=[\"y\"])\n",
    "y_test = pd.DataFrame([y for _, y in test_dataset], columns=[\"y\"])\n",
    "train_sample = y_train.groupby('y').sample(n=3, random_state=42).index\n",
    "test_sample = y_test.groupby('y').sample(n=3, random_state=42).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjKuM_HlhZZG"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 10))\n",
    "for i, idx in enumerate(train_sample):\n",
    "    image_t, label_idx = train_dataset[idx]\n",
    "    ax = fig.add_subplot(5, 50 // 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(image_t), cmap='gray')\n",
    "    ax.set_title(idx2label[label_idx])\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAY3f7HQcQP_"
   },
   "source": [
    "## Define the CNN Model and training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TApZ1lwRZyOa"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3FJLGAsZ4WL"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed_value: int):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def make_dataloader(dataset, batch_size, pin_memory=False, shuffle=False):\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=1,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_y(model, device, dataloader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    loss = 0\n",
    "    for (batch_input, batch_target) in tqdm(dataloader, total=len(dataloader), desc=\"get_y\", disable=True):\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "        predicted = model(batch_input)\n",
    "        loss += F.nll_loss(predicted, batch_target, reduction='sum').item()  # sum up batch loss\n",
    "        # get the index of the max log-probability\n",
    "        _y_true = batch_target.cpu().numpy()\n",
    "        _y_pred = predicted.argmax(dim=1).detach().cpu().numpy()\n",
    "        y_true.append(_y_true)\n",
    "        y_pred.append(_y_pred)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    return loss, y_true, y_pred\n",
    "\n",
    "\n",
    "def get_eval_metrics(y_true, y_pred):\n",
    "    return {\n",
    "      'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred),\n",
    "      'f1': f1_score(y_true=y_true, y_pred=y_pred, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred, prefix, loss=None):\n",
    "    metrics_to_log = {}\n",
    "    if loss is not None:\n",
    "        metrics_to_log[f\"{prefix}/loss\"] = loss\n",
    "    metrics = get_eval_metrics(y_true=y_true, y_pred=y_pred)\n",
    "    for k, v in metrics.items():\n",
    "        metrics_to_log[f'{prefix}/{k}'] = v\n",
    "    return metrics_to_log\n",
    "\n",
    "\n",
    "def get_plots(y_true, y_pred, labels=None):\n",
    "    plt.clf()\n",
    "    report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
    "    ax = sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)\n",
    "    ax.figure.tight_layout()\n",
    "    report_fig = plt.gcf()\n",
    "    plt.show()\n",
    "    z = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    cm_fig = px.imshow(\n",
    "        z,\n",
    "        text_auto=True,\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Productivity\"),\n",
    "        x=labels,\n",
    "        y=labels,\n",
    "        width=600,\n",
    "        height=600\n",
    "    )\n",
    "    cm_fig.show()\n",
    "    return report_fig, cm_fig\n",
    "\n",
    "\n",
    "  \n",
    "def get_images(dataset, sample, model, device, prefix):\n",
    "    images = {}\n",
    "    dataset = Subset(dataset, sample)\n",
    "    _, y_true, y_pred = get_y(model=model, device=device, dataloader=make_dataloader(dataset, batch_size=1000))\n",
    "    for sample_no, (image_t, _), actual_idx, prediction_idx  in zip(sample, dataset, y_true, y_pred):\n",
    "        images[f\"{prefix}_{sample_no}\"] = mlf.Image(\n",
    "            data_or_path=image_t.squeeze().numpy(),\n",
    "            caption=f\"{prefix}_{sample_no}\",\n",
    "            class_groups={\"actuals\": idx2label[actual_idx], \"predictions\": idx2label[prediction_idx]}\n",
    "        )\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnfRg5u7ONeh"
   },
   "source": [
    "## Log training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiOfHT0za6rL",
    "outputId": "a70dd40d-d06b-4a78-b963-5dc5d0fe2f9e"
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    batch_size=64,\n",
    "    test_batch_size=1000,\n",
    "    epochs=1,\n",
    "    lr=1.0,\n",
    "    gamma=0.7,\n",
    "    no_cuda=False,\n",
    "    seed=1,\n",
    "    log_interval=100,\n",
    "    save_model=True\n",
    ")\n",
    "\n",
    "run.log_params(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z0xtrR3OTk4"
   },
   "source": [
    "## Initialize Model, DataLoaders, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzKFGpoWpRTJ"
   },
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "num_classes = len(idx2label)\n",
    "set_random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c5QtELh5Fox"
   },
   "outputs": [],
   "source": [
    "# Make train and test dataloaders\n",
    "train_dataloader = make_dataloader(\n",
    "      train_dataset,\n",
    "      batch_size=args.batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=True\n",
    ")\n",
    "train_dataloader_for_eval = make_dataloader(\n",
    "      train_dataset,\n",
    "      batch_size=args.test_batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=False\n",
    ")\n",
    "test_dataloader = make_dataloader(\n",
    "      test_dataset,\n",
    "      batch_size=args.test_batch_size, \n",
    "      pin_memory=use_cuda, \n",
    "      shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPFIt0QY5HNt"
   },
   "outputs": [],
   "source": [
    "# Initialize model and loss\n",
    "model = Net(num_classes=num_classes)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TyFmJLL5KVH"
   },
   "outputs": [],
   "source": [
    "total_steps = args.epochs * len(train_dataloader)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "model = model.to(device)\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0glXr8-QOevu"
   },
   "source": [
    "## The Training loop\n",
    "## Here we will log metrics, plots and sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFscP9dS5NYu"
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, args.epochs + 1), desc=\"epochs\"):\n",
    "    epoch_start_time = timer()\n",
    "    epoch_loss = torch.tensor(0.0).to(device)\n",
    "    for _step, (batch_input, batch_target) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"steps\"):\n",
    "        model.train()\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "        batch_predicted = model(batch_input)\n",
    "        loss = criterion(batch_predicted, batch_target)        \n",
    "        \n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step % args.log_interval == 0:\n",
    "            #################### Logging Metrics ###############################\n",
    "            step_metrics = {\n",
    "                'step/lr': scheduler.get_last_lr()[0],\n",
    "                'train/step/loss': loss.item(),\n",
    "            }\n",
    "            _, y_true_train, y_pred_train = get_y(model, device, train_dataloader_for_eval)\n",
    "            step_metrics.update(get_metrics(y_true_train, y_pred_train, prefix=\"train/step\"))\n",
    "            test_loss, y_true_test, y_pred_test = get_y(model, device, test_dataloader)\n",
    "            step_metrics.update(get_metrics(y_true_test, y_pred_test, prefix=\"test/step\", loss=test_loss))\n",
    "\n",
    "            print(f'epoch={epoch} step={global_step}', step_metrics)\n",
    "            run.log_metrics(step_metrics, step=global_step)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ###################### Logging Metrics #####################################\n",
    "    epoch_loss = epoch_loss.item() / len(train_dataloader)\n",
    "    epoch_time = timer() - epoch_start_time\n",
    "    epoch_metrics = {\n",
    "        'epoch/epoch': epoch,\n",
    "        'epoch/lr': scheduler.get_last_lr()[0],\n",
    "        'train/epoch/loss': epoch_loss,\n",
    "        'epoch/time': epoch_time\n",
    "    }\n",
    "    _, y_true_train, y_pred_train = get_y(model, device, train_dataloader_for_eval)\n",
    "    epoch_metrics.update(get_metrics(y_true_train, y_pred_train, prefix=\"train/epoch\"))\n",
    "    test_loss, y_true_test, y_pred_test = get_y(model, device, test_dataloader)\n",
    "    epoch_metrics.update(get_metrics(y_true_test, y_pred_test, prefix=\"test/epoch\", loss=test_loss))\n",
    "    print(f'epoch={epoch} step={global_step}', epoch_metrics)\n",
    "\n",
    "    run.log_metrics(epoch_metrics, step=global_step)\n",
    "\n",
    "\n",
    "    ###################### Logging Plots #######################################\n",
    "    train_report_plt, train_cm_plt = get_plots(y_true=y_true_train, y_pred=y_pred_train, labels=idx2label)\n",
    "    test_report_plt, test_cm_plt = get_plots(y_true=y_true_test, y_pred=y_pred_test, labels=idx2label)\n",
    "    plots = {\n",
    "        'train_report': train_report_plt,\n",
    "        'train_confusion_matrix': train_cm_plt,\n",
    "        'test_report': test_report_plt,\n",
    "        'test_confusion_matrix': test_cm_plt,\n",
    "    }\n",
    "\n",
    "    run.log_plots(plots, step=global_step)\n",
    "    \n",
    "\n",
    "    ###################### Logging Images ######################################\n",
    "    train_images = get_images(dataset=train_dataset, sample=train_sample, model=model, device=device, prefix=\"train\")\n",
    "    test_images = get_images(dataset=test_dataset, sample=test_sample, model=model, device=device, prefix=\"test\")\n",
    "    images = {**train_images, **test_images}\n",
    "\n",
    "    run.log_images(images, step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOpe0pf6QS8o"
   },
   "source": [
    "## Log the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX7IQ1kvQT29"
   },
   "outputs": [],
   "source": [
    "if args.save_model:\n",
    "    model = model.to(torch.device(\"cpu\"))\n",
    "    run.log_model(model, framework=\"pytorch\", step=global_step)\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29dLGTCnO4Tq"
   },
   "source": [
    "## Log dataset stats with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d44yh7sP8MgZ"
   },
   "outputs": [],
   "source": [
    "columns = [f\"pix_{i}_{j}\" for i in range(28) for j in range(28)]\n",
    "train_dataloader = make_dataloader(train_dataset, batch_size=len(train_dataset))\n",
    "test_dataloader = make_dataloader(test_dataset, batch_size=len(test_dataset))\n",
    "X_train, _ = next(iter(train_dataloader))\n",
    "X_test, _ = next(iter(test_dataloader))\n",
    "X_train = pd.DataFrame(X_train.reshape(len(X_train), -1).numpy(), columns=columns)\n",
    "X_test = pd.DataFrame(X_test.reshape(len(X_test), -1).numpy(), columns=columns)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3mY8_lK_Nnn"
   },
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='train',\n",
    "    features=X_train[:500],\n",
    "    predictions=y_pred_train[:500],\n",
    "    actuals=y_true_train[:500],\n",
    "    only_stats=True,\n",
    ")\n",
    "\n",
    "run.log_dataset(\n",
    "    dataset_name='test',\n",
    "    features=X_test[:500],\n",
    "    predictions=y_pred_test[:500],\n",
    "    actuals=y_true_test[:500],\n",
    "    only_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kekmdY2HPCrt"
   },
   "source": [
    "## End the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZRWEjOmCcnV"
   },
   "outputs": [],
   "source": [
    "run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KXuzT7KPFso"
   },
   "source": [
    "# Deployment ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gk4u1cYTNKTC"
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"torch>=1.2.0,<2.0.0\" fastapi==0.78.0 python-multipart==0.0.5 scikit-image==0.19.3 gradio==3.0.24\n",
    "! pip install --quiet -U \"servicefoundry>=0.1.69,<0.2.0\" \"mlfoundry>=0.3.33,<0.4.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__kaenIggx3c",
    "outputId": "8263f61b-037b-46a5-8fd7-9aa6df7edbf7"
   },
   "outputs": [],
   "source": [
    "import servicefoundry.core as sfy\n",
    "sfy.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5VhmnQmtqSX"
   },
   "outputs": [],
   "source": [
    "WORKSPACE = 'v1:local:chirag-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTigA6ZR8WRw"
   },
   "source": [
    "## Deploy web service from predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "165RVxSvxtzS",
    "outputId": "c32e2159-fffb-4300-a6df-dbc98ff31e4f"
   },
   "outputs": [],
   "source": [
    "%%writefile predict.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import mlfoundry as mlf\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import fastapi\n",
    "import skimage.transform\n",
    "\n",
    "client = mlf.get_client(api_key=os.environ.get('TFY_API_KEY'))\n",
    "run = client.get_run(\"chiragjn/fashion-mnist-demo-trial/pytorch-cnn-2\")\n",
    "model = run.get_model(map_location=torch.device('cpu'))\n",
    "\n",
    "config_path = run.download_artifact(\"config.json\")\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "async def predict(image: fastapi.UploadFile = fastapi.File(...)):\n",
    "    data = await image.read()\n",
    "    np_image = np.array(Image.open(BytesIO(data)))\n",
    "    image = skimage.transform.resize(np_image, (28, 28))\n",
    "    image = image.reshape(1, 1, 28, 28)  # add a batch dimension\n",
    "    labels = config['idx2label']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(torch.Tensor(image))[0]\n",
    "    scores = np.exp(log_probs.detach().numpy()).tolist()\n",
    "    return {'predictions': dict(zip(labels, scores))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ikiFOSy9NT",
    "outputId": "4eb3fa45-5c12-4fb2-ecf8-fa85f041ee2c"
   },
   "outputs": [],
   "source": [
    "requirements = sfy.gather_requirements(\"predict.py\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSiVsxOI0gPM"
   },
   "outputs": [],
   "source": [
    "fastapi_service = sfy.Service(\"predict.py\", requirements, sfy.Parameters(\n",
    "    name=\"fashion-mnist-fastapi-service\",\n",
    "    workspace=WORKSPACE,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFSd5EGV1E7X",
    "outputId": "2aa358d9-a8cc-46e6-9698-3e35a2851340"
   },
   "outputs": [],
   "source": [
    "fastapi_service.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llT-DR-3LPeh"
   },
   "source": [
    "## Deploy model as a Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIM9Y9TJ2GK1",
    "outputId": "fc7348f2-74a0-4a23-921f-b2b9f92e4109"
   },
   "outputs": [],
   "source": [
    "%%writefile webapp.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlfoundry as mlf\n",
    "import gradio as gr\n",
    "\n",
    "client = mlf.get_client(api_key=os.environ.get('TFY_API_KEY'))\n",
    "run = client.get_run(\"chiragjn/fashion-mnist-demo-trial/pytorch-cnn-2\")\n",
    "model = run.get_model(map_location=torch.device('cpu'))\n",
    "\n",
    "config_path = run.download_artifact(\"config.json\")\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "def classify(image):\n",
    "    image = image[:, :, 0].reshape(1, 1, 28, 28)  #add a batch dimension\n",
    "    labels = config['idx2label']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(torch.Tensor(image))[0]\n",
    "    scores = np.exp(log_probs.detach().numpy()).tolist()\n",
    "    return dict(zip(labels, scores))\n",
    "\n",
    "\n",
    "inputs = gr.inputs.Image(shape=(28, 28))\n",
    "outputs = gr.outputs.Label(num_top_classes=10)\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=classify, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    title=\"Fashion MNIST Predictor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_T1n4QMLLGr",
    "outputId": "aad91785-6101-4bed-e494-a575f5c62da6"
   },
   "outputs": [],
   "source": [
    "requirements = sfy.gather_requirements(\"webapp.py\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BC4N7e7EPcui"
   },
   "outputs": [],
   "source": [
    "gradio_webapp = sfy.Gradio(\"webapp.py\", requirements, sfy.Parameters(\n",
    "    name=\"fashion-mnist-demo\",\n",
    "    workspace=WORKSPACE\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPUPcky-PifN",
    "outputId": "3203ada7-0aa0-45ad-87e5-2387f2701e41"
   },
   "outputs": [],
   "source": [
    "gradio_webapp.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJrY7uez8alR"
   },
   "source": [
    "## Deploy web service from predict function (image as str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6aP_mSvsg1X",
    "outputId": "12a73573-70d3-4b0f-b1f1-d85bba7efce8"
   },
   "outputs": [],
   "source": [
    "%%writefile predict.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import mlfoundry as mlf\n",
    "\n",
    "client = mlf.get_client(api_key=os.environ.get('TFY_API_KEY'))\n",
    "run = client.get_run(\"chiragjn/fashion-mnist-demo-trial/pytorch-cnn-2\")\n",
    "model = run.get_model(map_location=torch.device('cpu'))\n",
    "\n",
    "config_path = run.download_artifact(\"config.json\")\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "def predict(image: str):\n",
    "    data = base64.b64decode(image)\n",
    "    image = np.array(Image.open(io.BytesIO(data)))\n",
    "    image = image.reshape(1, 1, 28, 28)\n",
    "\n",
    "    labels = config['idx2label']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(torch.Tensor(image))[0]\n",
    "    scores = np.exp(log_probs.detach().numpy()).tolist()\n",
    "    return dict(zip(labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdYNdKIypfxk",
    "outputId": "7606d948-f3ac-41d9-b7ae-b540a24a524e"
   },
   "outputs": [],
   "source": [
    "requirements = sfy.gather_requirements(\"predict.py\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSH1jt9qxuyA"
   },
   "outputs": [],
   "source": [
    "auto_service = sfy.Service(\"predict.py\", requirements, sfy.Parameters(\n",
    "    name=\"fashion-mnist-service\",\n",
    "    workspace=WORKSPACE,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Ig7OfBDxuvH",
    "outputId": "48706608-5fbc-46f4-8b72-10516cd32d7b"
   },
   "outputs": [],
   "source": [
    "auto_service.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuOEe1HoxusS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "yT0FBE3PPRLz",
    "7KXuzT7KPFso",
    "lTigA6ZR8WRw",
    "hJrY7uez8alR",
    "aRdcq87t8QXm"
   ],
   "name": "train_and_deploy.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
