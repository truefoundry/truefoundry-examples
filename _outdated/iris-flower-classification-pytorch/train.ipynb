{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHAD7f2KjMed"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsAXCMvfbEos"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5I814E4jOZv"
      },
      "source": [
        "## Load dataset and split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evFYBiwsjA6n"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=2)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL7xdhiFjWk3"
      },
      "source": [
        "## Create an MLFoundry run and log dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "567woMSO82-a"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet \"mlfoundry>=0.3.33,<0.4.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC-gnRNGjVxS",
        "outputId": "bcdee85d-8e4a-44f1-d235-e826e69f6fbb"
      },
      "outputs": [],
      "source": [
        "import mlfoundry as mlf\n",
        "\n",
        "mlf.login()\n",
        "mlf_client = mlf.get_client()\n",
        "\n",
        "ML_FLOW = \"gh-demo-test\"\n",
        "run = mlf_client.create_run(ML_FLOW, \"base-run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDKx41ga9kZd",
        "outputId": "bf7c987c-86f2-4712-8586-d6fb374ad9c6"
      },
      "outputs": [],
      "source": [
        "run.log_dataset(\"train\", X_train, y_train)\n",
        "run.log_dataset(\"test\", X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRRyhi6BkAN8"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgJ6LRxhjBjN",
        "outputId": "0b99f590-cebe-4cfb-fff3-51fd4154bedb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 50)\n",
        "        self.layer2 = nn.Linear(50, 30)\n",
        "        self.layer3 = nn.Linear(30, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.softmax(self.layer3(x), dim=1)\n",
        "        return x\n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS  = 100\n",
        "\n",
        "model     = Model(X_train.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "loss_fn   = nn.CrossEntropyLoss()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3F5LHHtlJbI"
      },
      "source": [
        "## Log the hyper-parameters using MLFoundry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ferxq3NXlp2E",
        "outputId": "3742ae6b-e030-421d-fdbb-2586c570b288"
      },
      "outputs": [],
      "source": [
        "run.log_params({\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'epochs': EPOCHS\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROWLZdtiraQb",
        "outputId": "99a1f488-f45d-4e1f-8ed6-68a4ec13ebee"
      },
      "outputs": [],
      "source": [
        "run.set_tags({\n",
        "    'feature_names': feature_names,\n",
        "    'target_names': names\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avrSHWffnHHs"
      },
      "source": [
        "## Write a function to log confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ7qNb6wnGlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def log_confusion_matrix(y_true, y_pred, run=None, step=0):\n",
        "  fig, ax = plt.subplots(figsize=(5, 5))\n",
        "  ax.matshow(confusion_matrix(y_true, y_pred), cmap=plt.cm.Reds, alpha=0.5)\n",
        "  \n",
        "  if (run): run.log_plots({'confusion_matrix': fig}, step)\n",
        "\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsEjJ-jHlqNG"
      },
      "source": [
        "## Train the model\n",
        "After every epoch:\n",
        "  * Log metrics using `log_metrics`\n",
        "  * Log test dataset confusion matrix using `log_plots`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v7-7PmbzwHh"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = Variable(torch.from_numpy(X_train)).float()\n",
        "y_train_tensor = Variable(torch.from_numpy(y_train)).long()\n",
        "X_test_tensor  = Variable(torch.from_numpy(X_test)).float()\n",
        "y_test_tensor  = Variable(torch.from_numpy(y_test)).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSXKIwZjJn-",
        "outputId": "50a85b50-be00-4041-9d46-092e080af237"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline \n",
        "import tqdm\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "\n",
        "for epoch in tqdm.trange(EPOCHS):\n",
        "    y_pred = model(X_train_tensor)\n",
        "    loss = loss_fn(y_pred, y_train_tensor)\n",
        "\n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad() \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_train_pred = model(X_train_tensor)\n",
        "        y_test_pred = model(X_test_tensor)\n",
        "        \n",
        "        \n",
        "        train_correct = (torch.argmax(y_train_pred, dim=1) == y_train_tensor).type(torch.FloatTensor) \n",
        "        test_correct = (torch.argmax(y_test_pred, dim=1) == y_test_tensor).type(torch.FloatTensor)\n",
        "\n",
        "        # log metrics and plots every 10 epochs\n",
        "        if (epoch % 10 == 0):\n",
        "          log_confusion_matrix(y_test_tensor, torch.argmax(y_test_pred, dim=1), run, epoch)\n",
        "          run.log_metrics({\n",
        "              'loss': loss.item(),\n",
        "              'train/accuracy': train_correct.mean().item(),\n",
        "              'test/accuracy': test_correct.mean().item()\n",
        "          }, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItgG9A0MvPzt"
      },
      "source": [
        "## Searching for optimal hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKHd4qevOr2",
        "outputId": "02f09a5e-60d9-4b14-edca-cd4f158ace18"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATES = [0.001, 0.01, 0.1]\n",
        "EPOCHS_VALUES = [10, 100]\n",
        "\n",
        "for i, LR in enumerate(LEARNING_RATES):\n",
        "  for j, EPOCHS in enumerate(EPOCHS_VALUES):\n",
        "    run = mlf_client.create_run(ML_FLOW, f\"param-search-{i}-{j}\")\n",
        "\n",
        "    run.set_tags({\n",
        "        'type': 'param-search'\n",
        "    })\n",
        "\n",
        "    run.log_params({\n",
        "    'learning_rate': LR,\n",
        "    'epochs': EPOCHS\n",
        "    })\n",
        "\n",
        "    model     = Model(X_train.shape[1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    loss_fn   = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "      y_pred = model(X_train_tensor)\n",
        "      loss = loss_fn(y_pred, y_train_tensor)\n",
        "\n",
        "      # Zero gradients\n",
        "      optimizer.zero_grad() \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    y_test_pred = model(X_test_tensor)\n",
        "    test_correct = (torch.argmax(y_test_pred, dim=1) == y_test_tensor).type(torch.FloatTensor)\n",
        "\n",
        "    run.log_metrics({\n",
        "        'accuracy': test_correct.mean().item()\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV4zWky04ALh"
      },
      "outputs": [],
      "source": [
        "run.log_model(model, 'pytorch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj6A0RrkGmMw"
      },
      "source": [
        "## Deploy a demo app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIzvw9s9t8yW"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet gradio==3.0.13\n",
        "!pip install --quiet servicefoundry==0.1.65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daRkHa6St2g6"
      },
      "outputs": [],
      "source": [
        "import servicefoundry.core as sfy\n",
        "sfy.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANUjQDxR1_0L",
        "outputId": "4d7a09b8-9e4b-43db-d405-7108b4ddc49b"
      },
      "outputs": [],
      "source": [
        "%%writefile webapp.py\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import mlfoundry as mlf\n",
        "import torch\n",
        "import json\n",
        "\n",
        "CLASS_NAMES = ['setosa', 'versicolor', 'virginica']\n",
        "\n",
        "TFY_API_KEY = '<use-your-api-key>'\n",
        "RUN_ID = '<run_id-of-relevant-run>'\n",
        "\n",
        "client = mlf.get_client(api_key=TFY_API_KEY)\n",
        "run = client.get_run(RUN_ID)\n",
        "model = run.get_model()\n",
        "\n",
        "def predict_species(f1, f2, f3, f4):\n",
        "    y_pred = model(torch.Tensor([[f1, f2, f3, f4]]))\n",
        "    return CLASS_NAMES[torch.argmax(y_pred, dim=1)[0].item()]\n",
        "\n",
        "\n",
        "dataset = run.get_dataset('train')\n",
        "examples = dataset.features.sample(5).values.tolist()\n",
        "app = gr.Interface(fn=predict_species, title=\"Iris Classification\", inputs=[gr.Number(label=\"sepal length (cm)\"), gr.Number(label=\"sepal width (cm)\"), gr.Number(label=\"petal length (cm)\"), gr.Number(label=\"petal width (cm)\")], outputs=[gr.Textbox(label=\"Answer\")], examples=examples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gscf6-qBmPNZ"
      },
      "source": [
        "### Create a Servicefoundry workspace\n",
        "\n",
        "A Servicefoundry workspace is a collection of related services that share the same set of permissions.\n",
        "\n",
        "To create a workspace:\n",
        "\n",
        "1. Go to <a href=\"https://app.truefoundry.com/workspace\">ServiceFoundry dashboard</a>\n",
        "\n",
        "2. Click on `Create Workspace` to create a new workspace.\n",
        "\n",
        "3. Once the workspace is created, copy the FQN of the workspace. We shall use this to deploy our webapp and service to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8ncbYnGd3qd",
        "outputId": "b35e0197-e43f-432e-bceb-f8a8f2e8a98d"
      },
      "outputs": [],
      "source": [
        "WEBAPP_NAME = \"gradio-app\"\n",
        "WORKSPACE_FQN = input(\"Input workspace FQN copied from the dashboard \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8sS7QRueCUR",
        "outputId": "b469e6c4-70d3-4c7e-cf4c-d45c8f328748"
      },
      "outputs": [],
      "source": [
        "requirements = sfy.gather_requirements(\"webapp.py\")\n",
        "webapp = sfy.Gradio(\"webapp.py\", requirements, sfy.Parameters(\n",
        "    name=WEBAPP_NAME,\n",
        "    workspace=WORKSPACE_FQN,\n",
        "    cpu=sfy.CPU(required=1.0),\n",
        "    memory=sfy.Memory(required=1024 * 1000 * 1000)\n",
        "))\n",
        "\n",
        "webapp.deploy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyWqAqe09rvK"
      },
      "outputs": [],
      "source": [
        "# helper fn to generate service url\n",
        "def get_service_url(workspace_fqn, service_name):\n",
        "  _, cluster, ws_name = workspace_fqn.split(':')\n",
        "  return f'https://{service_name}-{ws_name}.{cluster}.production.truefoundry.cloud'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6StMz5M9sxW",
        "outputId": "f81a13e3-22c5-4515-a5cb-2c8f27186c33"
      },
      "outputs": [],
      "source": [
        "print(f'Once deployed, you can access the webapp at {get_service_url(WORKSPACE_FQN, WEBAPP_NAME)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "iris-mlfoundry.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
