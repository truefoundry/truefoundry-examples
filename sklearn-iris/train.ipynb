{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/mlfoundry-examples/blob/main/examples/sklearn/iris_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet \"numpy>=1.0.0,<2.0.0\" \"pandas>=1.0.0,<2.0.0\" \"matplotlib>=3.5.2,<3.6.0\" scikit-learn shap==0.40.0\n",
    "! pip install -U mlfoundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Login to MLFoundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mlfoundry login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Iris plants detection as a Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import mlfoundry as mlf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_iris()\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame, first using the feature data\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# Add a target column, and fill it with the target data\n",
    "df['target'] = data.target\n",
    "# Show the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Split Dataset into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the feature data\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "# store the target data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data using scikit-learn's train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)\n",
    "print('Train samples:', len(X_train))\n",
    "print('Test samples:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start MLFoundry Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlf.get_client()\n",
    "run = client.create_run(project_name='iris-sklearn-example', run_name='svm-model')\n",
    "print('RUN ID:', run.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Log the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='train',\n",
    "    features=X_train,\n",
    "    predictions=y_pred_train,\n",
    "    actuals=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_dataset(\n",
    "    dataset_name='test',\n",
    "    features=X_test,\n",
    "    predictions=y_pred_test,\n",
    "    actuals=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setting tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='scale', kernel='rbf', probability=True, C=1.2)\n",
    "run.set_tags({'framework': 'sklearn', 'task': 'classification'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training model, logging parameters and logging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(clf.get_params())\n",
    "run.log_params(clf.get_params())\n",
    "run.log_params({'classes': clf.classes_, 'features': clf.n_features_in_})\n",
    "run.log_model(clf, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Computing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'train/accuracy_score': accuracy_score(y_train, y_pred_train),\n",
    "    'train/f1_weighted': f1_score(y_train, y_pred_train, average='weighted'),\n",
    "    'train/f1_mirco': f1_score(y_train, y_pred_train, average='micro'),\n",
    "    'train/f1_macro': f1_score(y_train, y_pred_train, average='macro'),\n",
    "    'test/accuracy_score': accuracy_score(y_test, y_pred_test),\n",
    "    'test/f1_weighted': f1_score(y_test, y_pred_test, average='weighted'),\n",
    "    'test/f1_mirco': f1_score(y_test, y_pred_test, average='micro'),\n",
    "    'test/f1_macro': f1_score(y_test, y_pred_test, average='macro'),\n",
    "}\n",
    "print('Metrics', metrics)\n",
    "run.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32eca55f60ca0a4eb05caeb15f62cadd2ce358ded6aecd1922b0adda9a0225d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
