{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOAnoPl-dlSY"
   },
   "source": [
    "##### This notebook demonstrates a demo of how diabetes-regression model can be trained and deployed on truefoundry platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDl0VXdDdlSe"
   },
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/truefoundry-examples/blob/main/end-to-end-examples/diabetes-regression/diabetes_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnalU7uLTgmr",
    "outputId": "74d582b8-da4b-431d-f5f0-3ae11b35d718"
   },
   "outputs": [],
   "source": [
    "!pip install -U servicefoundry\n",
    "!pip install -U mlfoundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NN133xapzkt7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "[logging.root.removeHandler(h) for h in logging.root.handlers]\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(name)s] %(levelname)-8s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dSzNVdYDdlSj",
    "outputId": "60c41116-5c74-4ea9-b512-706ad4ee8896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'truefoundry-examples'...\n",
      "remote: Enumerating objects: 1630, done.\u001b[K\n",
      "remote: Counting objects: 100% (513/513), done.\u001b[K\n",
      "remote: Compressing objects: 100% (263/263), done.\u001b[K\n",
      "remote: Total 1630 (delta 263), reused 409 (delta 233), pack-reused 1117\u001b[K\n",
      "Receiving objects: 100% (1630/1630), 64.44 MiB | 11.97 MiB/s, done.\n",
      "Resolving deltas: 100% (841/841), done.\n",
      "/home/jovyan/truefoundry-examples\n",
      "/home/jovyan/truefoundry-examples/end-to-end-examples/diabetes-regression\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/truefoundry/truefoundry-examples.git\n",
    "%cd truefoundry-examples\n",
    "%cd end-to-end-examples/diabetes-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFAKTyETKX7_"
   },
   "source": [
    "### Workspace FQN\n",
    "Once you run the cell below you will get a prompt to enter your workspace. <br>\n",
    "* Step 1: Click on the link given in the prompt.\n",
    "* Step 2: Identify the Workspace you want to deploy the application in. \n",
    "* Step 3: Copy the Workspace FQN <br>\n",
    "![Copying Workspace FQN](https://files.readme.io/730fee2-Screenshot_2023-02-28_at_2.08.34_PM.png)\n",
    "* Step 4: Paste the Workspace FQN in the prompt and press enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YyzamMrzNqkS"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter you WORKSPACE_FQN (https://app.truefoundry.com/workspaces): ··························\n"
     ]
    }
   ],
   "source": [
    "# Copy workspace FQN from https://app.truefoundry.com/workspaces\n",
    "from getpass import getpass\n",
    "WORKSPACE=getpass(\"Please enter you WORKSPACE_FQN (https://app.truefoundry.com/workspaces):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2SBZldwNnKh"
   },
   "source": [
    "### API KEY\n",
    "Once you run the cell below you will get a prompt to enter your API KEY. <br>\n",
    "* Step 1: Click on the link given in the prompt.\n",
    "* Step 2: Click on Create New API Key button\n",
    "* Step 3: Enter the name you want to give to the API KEY and then click on generate\n",
    "* Step 4: Copy the API KEY, You can also download the API KEY for later use <br>\n",
    "![Copying API KEY](https://files.readme.io/201c8aa-Screenshot_2023-02-28_at_2.28.17_PM.png)\n",
    "* Step 5: Paste the API KEY in the prompt and press enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaYJ3QDRNmVQ",
    "outputId": "ab79a6ba-b7c4-44be-8227-363be9cf2f80"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your API Key (https://app.truefoundry.com/settings): ········································\n"
     ]
    }
   ],
   "source": [
    "TFY_API_KEY = getpass(\"Please enter your API Key (https://app.truefoundry.com/settings):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TFY_API_KEY\"] = TFY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter the ML repo name. You can create a new ML Repo from dashboard in the ML Repo section (Or enter any unique name, we will create a ML Repo for you):  diabetes-regression\n"
     ]
    }
   ],
   "source": [
    "ML_REPO_NAME = input(\"Please Enter the ML repo name. You can create a new ML Repo from dashboard in the ML Repo section (Or enter any unique name, we will create a ML Repo for you): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ML_REPO_NAME\"] = ML_REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivE5PJKDowFv"
   },
   "source": [
    "# ⚡ Training a ML Model using Jobs\n",
    "In this section we will deploy a training job that trains a SVM model on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6W3ZGvOCl_wF",
    "outputId": "c79632f7-89a6-48dc-acba-f4b54da04928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/truefoundry-examples/end-to-end-examples/diabetes-regression/train\n"
     ]
    }
   ],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2AgLSf1dlSn"
   },
   "source": [
    "### Training script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkdzTQuAdlSo",
    "outputId": "e792d1f9-86d8-4bcf-a700-bc824773fa3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlfoundry\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_diabetes\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcompose\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TransformedTargetRegressor\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpreprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m QuantileTransformer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SVR\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PredictionErrorDisplay\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(kernel: \u001b[36mstr\u001b[39;49;00m, n_quantiles: \u001b[36mint\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# load the dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    X, y = load_diabetes(as_frame=\u001b[34mTrue\u001b[39;49;00m, return_X_y=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# NOTE:- you can pass these configurations via command line\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# arguments, config file, environment variables.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    X_train, X_test, y_train, y_test = train_test_split(\u001b[37m\u001b[39;49;00m\n",
      "        X, y, test_size=\u001b[34m0.2\u001b[39;49;00m, random_state=\u001b[34m42\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# initialize the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    regressor = SVR(kernel=kernel)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# fit the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model = TransformedTargetRegressor(\u001b[37m\u001b[39;49;00m\n",
      "        regressor=regressor,\u001b[37m\u001b[39;49;00m\n",
      "        transformer=QuantileTransformer(n_quantiles=n_quantiles, output_distribution=\u001b[33m\"\u001b[39;49;00m\u001b[33mnormal\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    model.fit(X_train, y_train)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# get the predictions from the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    y_pred = model.predict(X_test)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# plot the confusion_matrix\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    PredictionErrorDisplay.from_predictions(\u001b[37m\u001b[39;49;00m\n",
      "        y_test,\u001b[37m\u001b[39;49;00m\n",
      "        y_pred,\u001b[37m\u001b[39;49;00m\n",
      "        kind=\u001b[33m\"\u001b[39;49;00m\u001b[33mactual_vs_predicted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        scatter_kwargs={\u001b[33m\"\u001b[39;49;00m\u001b[33malpha\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m0.5\u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create a run, setting the project's name the following run\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# should be associated with via setting the `ml_repo`\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# and the name of the run name via `run_name`\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    client = mlfoundry.get_client()\u001b[37m\u001b[39;49;00m\n",
      "    ml_repo = client.create_ml_repo(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mML_REPO_NAME\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    run = client.create_run(\u001b[37m\u001b[39;49;00m\n",
      "        ml_repo=ml_repo.name, run_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mSVR-with-QT\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the hyperparameters of the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    run.log_params(regressor.get_params())\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the metrics of the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    run.log_metrics({\u001b[33m\"\u001b[39;49;00m\u001b[33mscore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: model.score(X_test, y_test)})\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the associated plots\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    run.log_plots({\u001b[33m\"\u001b[39;49;00m\u001b[33mactual_vs_predicted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: plt})\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model_version = run.log_model(\u001b[37m\u001b[39;49;00m\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mdiabetes-regression\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        model=model,\u001b[37m\u001b[39;49;00m\n",
      "        framework=\u001b[33m\"\u001b[39;49;00m\u001b[33msklearn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        description=\u001b[33m\"\u001b[39;49;00m\u001b[33mSVC model trained on initial data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        model_schema={\u001b[37m\u001b[39;49;00m\n",
      "          \u001b[33m\"\u001b[39;49;00m\u001b[33mfeatures\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [\u001b[37m\u001b[39;49;00m\n",
      "            {\u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: c, \u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m} \u001b[34mfor\u001b[39;49;00m c \u001b[35min\u001b[39;49;00m X.columns\u001b[37m\u001b[39;49;00m\n",
      "          ],\u001b[37m\u001b[39;49;00m\n",
      "          \u001b[33m\"\u001b[39;49;00m\u001b[33mprediction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mnumeric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        },\u001b[37m\u001b[39;49;00m\n",
      "        custom_metrics=[{\u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mmean_square_error\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mmetric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalue_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}]\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mLogged model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_version.fqn\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# end the run\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    run.end()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# setup the argument parser by instantiating `ArgumentParser` class\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# add the following hyperparamters as arguments\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--kernel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mlinear\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--n_quantiles\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# get the `Namespace` of the arguments\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    args = parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# run the train function\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train(kernel=args.kernel, n_quantiles=args.n_quantiles)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSxhr7EXdlSp"
   },
   "source": [
    "### Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5VL2rY1dlSq",
    "outputId": "117d8fd0-9859-4284-8db1-0a9884ebfbd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==1.3.5\n",
      "scikit-learn==1.2.1\n",
      "mlfoundry>=0.7.2,<0.8.0\n",
      "matplotlib==3.2.2\n"
     ]
    }
   ],
   "source": [
    "!pygmentize requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1ePZ1gGdlSs"
   },
   "source": [
    "### Deployment using truefoundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "44a6ac9f95d44689b40705d1437998f7",
      "fdca6c9036cf4b9bac1ebafb8f7e8b91"
     ]
    },
    "id": "GpCF-gCddlSt",
    "outputId": "3e873565-2f5f-4f0c-c5c1-8a2010c94a76"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "from servicefoundry import Build, Job, PythonBuild, Param\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s', force=True)\n",
    "\n",
    "job = Job(\n",
    "    name=\"diabetes-reg-train\",\n",
    "    image=Build(\n",
    "        build_spec=PythonBuild(\n",
    "            command=\"python train.py --kernel {{kernel}} --n_quantiles {{n_quantiles}}\",\n",
    "            requirements_path=\"requirements.txt\",\n",
    "        )\n",
    "    ),\n",
    "    params=[\n",
    "            Param(name=\"n_quantiles\", default='100'),\n",
    "            Param(name=\"kernel\", default='linear', description=\"kernel for svm\"),\n",
    "        ],\n",
    "    env={\n",
    "        \"TFY_API_KEY\": os.environ['TFY_API_KEY'],\n",
    "        \"ML_REPO_NAME\": os.environ['ML_REPO_NAME']\n",
    "    },\n",
    ")\n",
    "\n",
    "deployment = job.deploy(workspace_fqn=WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o13fNn3odlSx"
   },
   "source": [
    "### Triggering a job's run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHXTXmREdlSy",
    "outputId": "5a6c838b-7834-41cb-d60e-fa01847482f2"
   },
   "outputs": [],
   "source": [
    "from servicefoundry import trigger_job\n",
    "\n",
    "APPLICATION_FQN=\"demo-euwe1-production:demos:diabetes-reg-train\"\n",
    "\n",
    "# Use the `trigger_job()` function to trigger a job run with different kernel values\n",
    "for kernel in [\"linear\", \"rbf\", \"poly\"]:\n",
    "    trigger_job(application_fqn=APPLICATION_FQN, params = {\"kernel\": kernel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDgTLGNHta97"
   },
   "source": [
    "# ☁ Deploy ML Model using a Service (FastAPI)\n",
    "In this section we will deploy the model trained and logged by our training job as an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGSb4MUmdlSz"
   },
   "source": [
    "### Writing a fastapi service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGYMQMYWuOEx",
    "outputId": "a4c22dcf-3322-4552-e7b6-ef25c59d49bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/truefoundry-examples/end-to-end-examples/diabetes-regression/service-deploy\n"
     ]
    }
   ],
   "source": [
    "%cd ../service-deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxCsl9MFdlS2",
    "outputId": "49ebf951-1085-4078-bb51-675d9aa849d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtyping\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m List\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36muuid\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datetime\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlfoundry\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmlf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpydantic\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BaseModel\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastapi\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m FastAPI\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# instantiate the FastAPI application via `FastAPI`\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "app = FastAPI(docs_url=\u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# get the model from `Truefoundry Model Registry`\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "MODEL_VERSION_FQN = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMODEL_VERSION_FQN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "client = mlf.get_client()\u001b[37m\u001b[39;49;00m\n",
      "model = client.get_model(MODEL_VERSION_FQN).load()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# define pydantic classes for the Instance, Request and Response\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mInstance\u001b[39;49;00m(BaseModel):\u001b[37m\u001b[39;49;00m\n",
      "    age: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    sex: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    bmi: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    bp: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s1: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s2: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s3: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s4: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s5: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    s6: \u001b[36mfloat\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mRequest\u001b[39;49;00m(BaseModel):\u001b[37m\u001b[39;49;00m\n",
      "    instances: List[Instance]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mResponse\u001b[39;49;00m(BaseModel):\u001b[37m\u001b[39;49;00m\n",
      "    predictions: List[\u001b[36mfloat\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# defining a fastapi endpoint for predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[90m@app\u001b[39;49;00m.post(\u001b[33m\"\u001b[39;49;00m\u001b[33m/predict\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, response_model=Response)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(request: Request):\u001b[37m\u001b[39;49;00m\n",
      "    features = request.dict()[\u001b[33m\"\u001b[39;49;00m\u001b[33minstances\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create a dataframe out of the features dictionary\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    features_df = pd.DataFrame(features)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# get the predictions from the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    predictions = [\u001b[36mfloat\u001b[39;49;00m(p) \u001b[34mfor\u001b[39;49;00m p \u001b[35min\u001b[39;49;00m model.predict(features_df)]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# use the mlfoundry client to log the predictions\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    client.log_predictions(\u001b[37m\u001b[39;49;00m\n",
      "        model_version_fqn=MODEL_VERSION_FQN,\u001b[37m\u001b[39;49;00m\n",
      "        predictions=[\u001b[37m\u001b[39;49;00m\n",
      "            mlf.Prediction(\u001b[37m\u001b[39;49;00m\n",
      "                data_id=uuid.uuid4().hex,\u001b[37m\u001b[39;49;00m\n",
      "                features=feature,\u001b[37m\u001b[39;49;00m\n",
      "                prediction_data={\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: prediction,\u001b[37m\u001b[39;49;00m\n",
      "                },\u001b[37m\u001b[39;49;00m\n",
      "                occurred_at=datetime.utcnow(),\u001b[37m\u001b[39;49;00m\n",
      "                raw_data={\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33many_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "            )\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mfor\u001b[39;49;00m feature, prediction \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(features, predictions)\u001b[37m\u001b[39;49;00m\n",
      "        ],\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m Response(predictions=predictions)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Ka_3O6dlS2"
   },
   "source": [
    "### Requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9L4aNn7dlS4",
    "outputId": "f8ce52d1-4cc1-4405-8b00-f49662016f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==1.3.5\n",
      "scikit-learn==1.2.1\n",
      "mlfoundry>=0.7.2,<0.8.0\n",
      "fastapi==0.81.0\n",
      "uvicorn==0.18.3\n"
     ]
    }
   ],
   "source": [
    "!pygmentize requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pve8p9w0dlS5"
   },
   "source": [
    "### Deploying Model as a service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_77jVAYu163A"
   },
   "source": [
    "#### MODEL VERSION FQN\n",
    "Once you run the cell below you will get a prompt to enter your MODEL VERSION FQN. <br>\n",
    "* Step 1: Click on the link given in the prompt.\n",
    "* Step 2: Click on the Project Name (e.g. diabetes-regression)\n",
    "* Step 3: Click the run with the highest score.\n",
    "* Step 4: Click on the Model's tab.\n",
    "* Step 5: Copy the MODEL VERSION FQN<br>\n",
    "![Copying MODEL VERSION FQN](https://files.readme.io/9f726f6-Screenshot_2023-03-14_at_2.39.27_PM.png)\n",
    "* Step 6: Paste the MODEL VERSION FQN in the prompt and press enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nvcm1rEiPkri",
    "outputId": "163c6640-7ad9-4542-b8ca-97f8eb940799"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the model version fqn: (https://app.truefoundry.com/mlfoundry) model:truefoundry/truefoundry-demo/diabetes-regression/diabetes-regression:2\n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION_FQN = input(\"Please enter the model version fqn: (https://app.truefoundry.com/mlfoundry)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4578ab6cb6414370bd04aebfd2ae3265",
      "5aa3efc745f54970adba6b16f5597c28"
     ]
    },
    "id": "bjNTxbRuyDQu",
    "outputId": "10611f4a-98f6-4c05-f1d2-bc0156b03d91"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from servicefoundry import Build, Service, PythonBuild, Resources\n",
    "\n",
    "#Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s', force=True)\n",
    "\n",
    "service = Service(\n",
    "    name=\"diabetes-reg-fastapi\",\n",
    "    image=Build(\n",
    "        # Specify the build_specifications using `PythonBuild` to define we need a python environment\n",
    "        build_spec=PythonBuild(\n",
    "            command=\"uvicorn main:app --port 8000 --host 0.0.0.0\",\n",
    "        )\n",
    "    ),\n",
    "    ports=[{\"port\": 8000, \"host\": \"diabetes-reg-fastapi.demo1.truefoundry.com\"}],\n",
    "    # Specify the environment variables\n",
    "    env={\n",
    "        \"TFY_API_KEY\": TFY_API_KEY,\n",
    "        \"MODEL_VERSION_FQN\": MODEL_VERSION_FQN\n",
    "    },\n",
    "    resources=Resources(cpu_limit=0.2, cpu_request=0.2, memory_request=600, memory_limit=600, ephemeral_storage_limit=200, ephemeral_storage_request=200),\n",
    ")\n",
    "# Deploy the service using the `.deploy()` method\n",
    "deployment = service.deploy(workspace_fqn=WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIxHMOaJeUt2"
   },
   "source": [
    "# ☁ Deploy a batch-prediction job\n",
    "In this section we deploy a batch prediction job which will load the model, make the predictions and log the data in monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRpaldc8dlS8"
   },
   "source": [
    "### Script to load the model and make predictions on a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTZc6O3xdlS8",
    "outputId": "4c3f00a4-0cdb-4066-f6cb-799e002c1904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/truefoundry-examples/end-to-end-examples/diabetes-regression/batch-inference\n"
     ]
    }
   ],
   "source": [
    "%cd ../batch-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00Qf2sS_dlS9",
    "outputId": "05c582da-ca68-495e-c28f-8da75dd6a583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlfoundry\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmlf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36muuid\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m  \u001b[34mimport\u001b[39;49;00m datetime\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_diabetes\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# get the model from `Truefoundry Model Registry`.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "MODEL_VERSION_FQN = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mMODEL_VERSION_FQN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "client = mlf.get_client()\u001b[37m\u001b[39;49;00m\n",
      "model_version = client.get_model(MODEL_VERSION_FQN)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "model_schema = model_version.model_schema\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# load the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "model = model_version.load()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# load the dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "X, y = load_diabetes(as_frame=\u001b[34mTrue\u001b[39;49;00m, return_X_y=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# we are sampling a smaller version of the dataset for demonstration purposes\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "X_sampled = X.sample(n=\u001b[34m6\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "y_sampled = y[X_sampled.index]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# make predictions from the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "y_pred = model.predict(X_sampled)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# parse the predictions in `mlfoundry.Prediction` format\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "predictions = []\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m6\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "    row = X_sampled.iloc[i]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create a dictionary of features\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    features_dict = {}\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m feature \u001b[35min\u001b[39;49;00m model_schema.features:\u001b[37m\u001b[39;49;00m\n",
      "        features_dict[feature.name] = \u001b[36mfloat\u001b[39;49;00m(row[feature.name])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#append `mlf.Prediction` objects in predictions list\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    predictions.append(mlf.Prediction(\u001b[37m\u001b[39;49;00m\n",
      "        data_id=uuid.uuid4().hex,\u001b[37m\u001b[39;49;00m\n",
      "        features=features_dict,\u001b[37m\u001b[39;49;00m\n",
      "        prediction_data={\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[36mfloat\u001b[39;49;00m(y_pred[i]),\u001b[37m\u001b[39;49;00m\n",
      "        },\u001b[37m\u001b[39;49;00m\n",
      "        actual_value=\u001b[36mfloat\u001b[39;49;00m(y_sampled.iloc[i]),\u001b[37m\u001b[39;49;00m\n",
      "        occurred_at=datetime.utcnow(),\u001b[37m\u001b[39;49;00m\n",
      "        raw_data={\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33many_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "    ))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# log the predictions using the client\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "client.log_predictions(model_version_fqn=MODEL_VERSION_FQN, predictions=predictions)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tSxswwXdlS_"
   },
   "source": [
    "### Requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lg9zDZVfdlTB",
    "outputId": "d6f5ad05-3f1d-4db2-d4c6-da9e86466c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.2.1\n",
      "mlfoundry>=0.7.2,<0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pygmentize requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E30Ud1QQdlTC"
   },
   "source": [
    "### Deploying the batch prediction job as a cron job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c45323be56c2418394b1d2d011819c7e",
      "29e743ac9cde426fb8a3183f996e0c46"
     ]
    },
    "id": "PypArKKLdlTF",
    "outputId": "55521080-af7d-4825-e543-a3a9e40c6930"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from servicefoundry import Build, Job, PythonBuild, Schedule\n",
    "\n",
    "#Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "#Now we need to define the properties of the Job, using the `Job` class\n",
    "job = Job(\n",
    "    # Specifies what the name/identifier of the job should be\n",
    "    name=\"diabetes-reg-batch\",\n",
    "    # Now we need to define the how to build our code into a Docker image, using `Build` class \n",
    "    image=Build(\n",
    "        # Specify the build_specifications using `PythonBuild` to define we need a python environment\n",
    "        build_spec=PythonBuild(command=\"python main.py\"),\n",
    "    ),\n",
    "    # Specify the environment variables\n",
    "    env={\n",
    "        \"MODEL_VERSION_FQN\": MODEL_VERSION_FQN,\n",
    "        \"TFY_API_KEY\": TFY_API_KEY\n",
    "    },\n",
    "    # To setup a Cron Job (Repeating Job), we will use the `Schedule` class.\n",
    "    # You will use the `Schedule` class to specify the schedule of the Cron job.\n",
    "    # Inside `Schedule` class you can pass the schedule argument. It takes the value in [Cron Format](https://docs.truefoundry.com/docs/deploy-a-cron-job#understanding-the-cron-format)\n",
    "    trigger=Schedule(schedule=\"*/10 * * * *\"),\n",
    ")\n",
    "# Deploy the job using the `.deploy()` method.\n",
    "job.deploy(workspace_fqn=WORKSPACE)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "29e743ac9cde426fb8a3183f996e0c46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a6ac9f95d44689b40705d1437998f7": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_fdca6c9036cf4b9bac1ebafb8f7e8b91",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠸</span> Current state: BUILDING\n</pre>\n",
         "text/plain": "\u001b[32m⠸\u001b[0m Current state: BUILDING\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "4578ab6cb6414370bd04aebfd2ae3265": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_5aa3efc745f54970adba6b16f5597c28",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> Current state: BUILDING\n</pre>\n",
         "text/plain": "\u001b[32m⠙\u001b[0m Current state: BUILDING\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5aa3efc745f54970adba6b16f5597c28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c45323be56c2418394b1d2d011819c7e": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_29e743ac9cde426fb8a3183f996e0c46",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠙</span> Current state: BUILDING\n</pre>\n",
         "text/plain": "\u001b[32m⠙\u001b[0m Current state: BUILDING\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "fdca6c9036cf4b9bac1ebafb8f7e8b91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
