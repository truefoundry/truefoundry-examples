{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiNXch0wrA4Q",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### This notebook demonstrates a demo of how churn-prediction model can be trained and deployed on truefoundry platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JI8jciawrA4R",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Try this Notebook in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truefoundry/truefoundry-examples/blob/main/end-to-end-examples/churn-prediction/truefoundry-churn-prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c6nhZIxSvl2",
    "tags": []
   },
   "source": [
    "# 🛠 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnalU7uLTgmr",
    "outputId": "6eb49ff0-9e66-4f43-9381-4fd04867246d"
   },
   "outputs": [],
   "source": [
    "pip install -U servicefoundry mlfoundry --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NN133xapzkt7"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "[logging.root.removeHandler(h) for h in logging.root.handlers]\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(name)s] %(levelname)-8s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyzamMrzNqkS",
    "outputId": "cddb17d7-5bb5-4b0e-9c09-04dcf39de2da"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "WORKSPACE = input(\"Enter Your Workspace FQN here: \")\n",
    "\n",
    "os.environ[\"TFY_HOST\"] = \"<Enter the url of your Truefoundry Dashboard here>\"\n",
    "os.environ[\"TFY_API_KEY\"] = getpass(\"Please enter your API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrS7XolGrA4U",
    "outputId": "139c6a08-1f56-4e45-c1e5-d3d461e70346"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/truefoundry/truefoundry-examples.git\n",
    "%cd truefoundry-examples\n",
    "%cd end-to-end-examples/churn-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SC-s8sCY-QN",
    "tags": []
   },
   "source": [
    "# ⚡ Deploying a training Job - Quick Start\n",
    "Here we will create a training job that will run on truefoundry's infrastructure and save the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3CsMZw0rA4U",
    "tags": []
   },
   "source": [
    "### Training Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fyQxCNBgrA4V",
    "outputId": "50861ffb-4bf8-443b-abf0-617f71029fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/truefoundry-examples/end-to-end-examples/churn-prediction/train\n"
     ]
    }
   ],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elFpXLl2ZS0g",
    "outputId": "b27e412c-7fdf-4888-dd95-2030a82b74aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mneighbors\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m KNeighborsClassifier \u001b[34mas\u001b[39;49;00m Classification\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlfoundry\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmlf\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mexperiment_track\u001b[39;49;00m(model, params, metrics, X_train, X_test):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# initialize the mlfoundry client.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_api = mlf.get_client()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create a ml repo\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_api.create_ml_repo(\u001b[33m\"\u001b[39;49;00m\u001b[33mchurn-pred\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# create a run\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_run = mlf_api.create_run(\u001b[37m\u001b[39;49;00m\n",
      "        ml_repo=\u001b[33m\"\u001b[39;49;00m\u001b[33mchurn-pred\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, run_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mchurn-train-job\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_run.log_params(params)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the metrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_run.log_metrics(metrics)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model_version = mlf_run.log_model(\u001b[37m\u001b[39;49;00m\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mchurn-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        model=model,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# specify the framework used (in this case sklearn)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        framework=mlf.ModelFramework.SKLEARN,\u001b[37m\u001b[39;49;00m\n",
      "        description=\u001b[33m\"\u001b[39;49;00m\u001b[33mchurn-prediction-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# log the plots\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    mlf_run.log_plots({\u001b[33m\"\u001b[39;49;00m\u001b[33mconfusion_matrix\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: plt}, step=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# return the model's fqn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model_version.fqn\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain_model\u001b[39;49;00m(hyperparams):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    df = pd.read_csv(\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://raw.githubusercontent.com/nikp1172/datasets-sample/main/Churn_Modelling.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    X = df.iloc[:, \u001b[34m3\u001b[39;49;00m:-\u001b[34m1\u001b[39;49;00m].drop([\u001b[33m\"\u001b[39;49;00m\u001b[33mGeography\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mGender\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    y = df.iloc[:, -\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Create train test split\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[34m0.2\u001b[39;49;00m, random_state=\u001b[34m42\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Initialize the KNN Classifier\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    classifier = Classification(\u001b[37m\u001b[39;49;00m\n",
      "        n_neighbors=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mn_neighbors\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        weights=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mweights\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        algorithm=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33malgorithm\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        p=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mpower\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        leaf_size=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mleaf_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        metric=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mmetric\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        n_jobs=hyperparams[\u001b[33m'\u001b[39;49;00m\u001b[33mn_jobs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Fit the classifier with the training data\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    classifier.fit(X_train, y_train)\u001b[37m\u001b[39;49;00m\n",
      "    y_pred = classifier.predict(X_test)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Get the ground truth labels\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    labels = \u001b[36mlist\u001b[39;49;00m(\u001b[36mset\u001b[39;49;00m(y))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Plot the confusion matrix\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    cm = confusion_matrix(y_test, y_pred, labels=labels)\u001b[37m\u001b[39;49;00m\n",
      "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=\u001b[36mlist\u001b[39;49;00m(\u001b[36mset\u001b[39;49;00m(y)))\u001b[37m\u001b[39;49;00m\n",
      "    disp.plot()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Get the metrics\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    metrics = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: accuracy_score(y_test, y_pred),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mf1_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: f1_score(y_test, y_pred, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mweighted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mprecision\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: precision_score(y_test, y_pred, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mweighted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mrecall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: recall_score(y_test, y_pred, average=\u001b[33m\"\u001b[39;49;00m\u001b[33mweighted\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Log the experiment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    experiment_track(classifier, classifier.get_params(), metrics, X_train, X_test)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Setup the argument parser by instantiating `ArgumentParser` class\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Add the hyperparamters as arguments\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--n_neighbors\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--weights\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--algorithm\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--power\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--leaf_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--metric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--n_jobs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        required=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    args = parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "    hyperparams = \u001b[36mvars\u001b[39;49;00m(args)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_model(hyperparams)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBA1sWmRrA4V",
    "tags": []
   },
   "source": [
    "### Defining the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PIIG4CKIrA4V",
    "outputId": "5b2b95d0-e67f-4a69-b896-ba6949b2c15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib==3.1.3\n",
      "matplotlib-inline==0.1.6\n",
      "mlfoundry>=0.7.2,<0.8.0\n",
      "pandas==1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pygmentize requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujiWtfkPrA4V",
    "tags": []
   },
   "source": [
    "### Deploy as a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y593_mW6rA4V"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from servicefoundry import Build, PythonBuild, Resources, Job, Param, LocalSource\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Defining the job\n",
    "job = Job(\n",
    "    name=\"churn-prediction-train\",\n",
    "    image=Build(\n",
    "        build_spec=PythonBuild(\n",
    "            command=\"python main.py --n_neighbors {{n_neighbors}} --weights {{weights}} --algorithm {{algorithm}} --power {{power}} --leaf_size {{leaf_size}} --metric {{metric}} --n_jobs {{n_jobs}}\",\n",
    "            requirements_path=\"requirements.txt\",\n",
    "        ) ,\n",
    "        build_source=LocalSource(local_build=False)\n",
    "    ),\n",
    "    params=[\n",
    "        Param(name=\"n_neighbors\", default='5', description=\"Number of neighbors to use by default\"),\n",
    "        Param(name=\"weights\", default='uniform', description=\"Weight function used in prediction.  Possible values: uniform, distance\"),\n",
    "        Param(name=\"algorithm\", default='auto', description=\"Algorithm used to compute the nearest neighbors: possible values: 'auto', 'ball_tree', 'kd_tree', 'brute'\"),\n",
    "        Param(name=\"power\", default='2', description=\"Power parameter for the Minkowski metric. When p = 1, this is manhattan_dist, and euclidean_dist p = 2\"),\n",
    "        Param(name=\"leaf_size\", default='30', description=\"Leaf size passed to BallTree or KDTree\"),\n",
    "        Param(name=\"metric\", default='minkowski', description=\"The distance metric to use for the tree. The default metric is minkowski,\"),\n",
    "        Param(name=\"n_jobs\", default='1', description=\"The number of parallel jobs to run for neighbors search\"),\n",
    "    ],\n",
    "    resources=Resources(\n",
    "        cpu_request=1, cpu_limit=1, memory_request=2000, memory_limit=2000,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Finally, we call deploy to push it to Truefoundry platform\n",
    "deployment = job.deploy(workspace_fqn=WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPvVujwDrA4V",
    "tags": []
   },
   "source": [
    "# Trigger the training runs\n",
    "To trigger the job from UI:\n",
    "Click on https://app.truefoundry.com/deployments?tab=jobs and trigger a run.\n",
    "\n",
    "For triggering from python-sdk, run the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Md_3NdwjrA4V",
    "outputId": "0bfcb492-95e0-4df6-85d8-bfe2758f59f1"
   },
   "outputs": [],
   "source": [
    "from servicefoundry import trigger_job\n",
    "\n",
    "application_fqn = \"ctl-demo:demo:churn-prediction-train\"\n",
    "trigger_job(\n",
    "    application_fqn=application_fqn,\n",
    "    params={\n",
    "        \"n_neighbors\": \"4\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1maCwoHrA4V"
   },
   "source": [
    "## Train Multiple Models with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uUPtsP4rA4V",
    "outputId": "339d3549-2ba8-4d37-c153-7173c22aa86e"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# modeify to dict\n",
    "hyperparameters = {\n",
    "    'n_neighbors': [\"5\", \"10\", \"15\"],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'power': ['1', '2'],\n",
    "    'leaf_size': ['30', '40'],\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "}\n",
    "\n",
    "# generate all possible combinations using itertools\n",
    "values = list(product(*hyperparameters.values()))\n",
    "\n",
    "for value in values:\n",
    "    # convert to dict\n",
    "    params = dict(zip(hyperparameters.keys(), value))\n",
    "    trigger_job(\n",
    "        application_fqn=application_fqn,\n",
    "        params=params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etyus4gpQXlJ",
    "tags": []
   },
   "source": [
    "# ☁ Deploying the trained Model\n",
    "Here we will deploy the model saved in truefoundry's model registry at the time of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS8oSnJIrA4W",
    "outputId": "9bca224d-4e91-494a-c68d-0da982fd8ed3"
   },
   "outputs": [],
   "source": [
    "MODEL_VERSION_FQN = input(\"Please enter the model version fqn:-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hXhrrbIQXlW",
    "outputId": "6e26ae70-7382-4825-847b-1098477523b9"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from servicefoundry import ModelDeployment, Resources, TruefoundryModelRegistry, Endpoint\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model_deployment = ModelDeployment(\n",
    "    name=f\"churn-prediction\",\n",
    "    model_source=TruefoundryModelRegistry(model_version_fqn=MODEL_VERSION_FQN),\n",
    "    resources=Resources(cpu_request=0.2, cpu_limit=0.5, memory_request=500, memory_limit=1000),\n",
    "    endpoint=Endpoint(host=\"churn-prediction-model-demo.demo2.truefoundry.tech\")\n",
    ")\n",
    "\n",
    "model_deployment.deploy(workspace_fqn=WORKSPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wznSUHzGrA4W"
   },
   "source": [
    "## Lets try out the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "27cGkDVmrA4W",
    "outputId": "deb5c71d-ca7f-44b2-e3b3-29b830e01525"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the deployed url for the model https://churn-prediction-model-demo.demo2.truefoundry.tech\n"
     ]
    }
   ],
   "source": [
    "model_deployed_url = input(\"Enter the deployed url for the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9dsKK1jJrA4W"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def _predict(input_dict, model_deployed_url):\n",
    "    json_body = {\n",
    "        \"parameters\": {\n",
    "            \"content_type\": \"pd\"\n",
    "        },\n",
    "        \"inputs\": []\n",
    "    }\n",
    "\n",
    "    for k, v in input_dict.items():\n",
    "        json_body[\"inputs\"].append(\n",
    "            {\n",
    "                \"name\": k,\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": [v],\n",
    "                \"shape\": [1]\n",
    "            }\n",
    "        )\n",
    "    response = requests.post(\n",
    "        url=f\"{model_deployed_url}/v2/models/churn-model/infer\",\n",
    "        json=json_body\n",
    "    )\n",
    "    return response.json()[\"outputs\"][0][\"data\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFUs3WfXrA4W",
    "outputId": "6f39fb9c-342e-4bef-91e0-b679c3ce4016"
   },
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"CreditScore\": 700,\n",
    "    \"Age\": 42,\n",
    "    \"Tenure\": 2,\n",
    "    \"Balance\": 1000000,\n",
    "    \"NumOfProducts\": 1,\n",
    "    \"HasCrCard\": 1,\n",
    "    \"IsActiveMember\": 0,\n",
    "    \"EstimatedSalary\": 10948.88\n",
    "}\n",
    "\n",
    "output = _predict(input_dict, model_deployed_url)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivE5PJKDowFv",
    "tags": []
   },
   "source": [
    "#  ☁  Deploying  Model's Demo as a Service\n",
    "In this section we will deploy a training job that trains a SVM model on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6W3ZGvOCl_wF",
    "outputId": "703fc603-42fe-429c-c166-6cb730b630f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/truefoundry-examples/end-to-end-examples/churn-prediction/demo\n"
     ]
    }
   ],
   "source": [
    "%cd ../demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfSfEhq1rA4W"
   },
   "source": [
    "### Creating a gradio demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZasQomLprA4W",
    "outputId": "df33be4e-3441-44d4-a41c-bd9c20a2bec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgradio\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mgr\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrequests\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36murllib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparse\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m urljoin\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Endpoint of the deployed model\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "MODEL_DEPLOYED_URL = os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mMODEL_DEPLOYED_URL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# specifying the desired input components\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "inputs = [\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mCreditScore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m619\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mAge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m42\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mTenure\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m2\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mBalance\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m0\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mNumOfProducts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m1\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mHasCrCard\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m1\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mIsActiveMember\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m1\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    gr.Number(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mEstimatedSalary\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, value=\u001b[34m101348.88\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(*val):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# request body in dictionary format\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    json_body = {\u001b[33m\"\u001b[39;49;00m\u001b[33mparameters\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mcontent_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mpd\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    }, \u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: []}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# add the values into inputs list of json_body\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m v, inp \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(val, inputs):\u001b[37m\u001b[39;49;00m\n",
      "        json_body[\u001b[33m\"\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].append(\u001b[37m\u001b[39;49;00m\n",
      "            {\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: inp.label,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mdatatype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mFP32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [v],\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: [\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "            }\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# use the requests library, post the request and get the response\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    resp = requests.post(\u001b[37m\u001b[39;49;00m\n",
      "        url=urljoin(MODEL_DEPLOYED_URL, \u001b[33m\"\u001b[39;49;00m\u001b[33mv2/models/churn-model/infer\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        json=json_body\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    r = resp.json()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# return the output and model_version\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m [ r[\u001b[33m\"\u001b[39;49;00m\u001b[33moutputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m],  r[\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_version\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# description for the gradio application\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "desc = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\u001b[33m## Demo Deployed at \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdatetime.datetime.now().strftime(\u001b[33m\"\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mm/\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mY \u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mH:\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mM:\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# setup Gradio Interface\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "app = gr.Interface(\u001b[37m\u001b[39;49;00m\n",
      "    fn=predict,\u001b[37m\u001b[39;49;00m\n",
      "    inputs=inputs,\u001b[37m\u001b[39;49;00m\n",
      "    outputs=[gr.Textbox(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mChurn\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), gr.Textbox(label=\u001b[33m\"\u001b[39;49;00m\u001b[33mModel Version\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)],\u001b[37m\u001b[39;49;00m\n",
      "    description=desc,\u001b[37m\u001b[39;49;00m\n",
      "    title=\u001b[33m\"\u001b[39;49;00m\u001b[33mChurn Predictor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      ")\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# launch the gradio interface\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "app.launch(server_name=\u001b[33m\"\u001b[39;49;00m\u001b[33m0.0.0.0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, server_port=\u001b[34m8080\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWVnR6b-rA4W"
   },
   "source": [
    "### Defining the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yT6ov99NrA4W",
    "outputId": "049f5ca0-9ac7-44d2-f4e8-53354f63c28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests==2.28.1\n",
      "gradio==3.17.1\n",
      "urllib3==1.26.12\n"
     ]
    }
   ],
   "source": [
    "!pygmentize requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22EVm-3drA4W"
   },
   "source": [
    "### Deploying the gradio demo as a 'Service'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fbjqAsGmrA4W",
    "outputId": "ae7684d9-ce80-4088-87e3-e5b5ddf759ac"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the deployed url for model (found on dashboard) https://churn-prediction-model-demo.demo2.truefoundry.tech\n"
     ]
    }
   ],
   "source": [
    "MODEL_DEPLOYED_URL = input(\"Please enter the deployed url for model (found on dashboard)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPpvlO-wrA4X",
    "outputId": "5ca1ddc9-a9cc-4aa6-80b7-dc0748597251"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from servicefoundry import Build, PythonBuild, Resources, Service\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# creating a service object and defining all the configurations\n",
    "service = Service(\n",
    "    name=\"churn-prediction-demo\",\n",
    "    image=Build(\n",
    "        build_spec=PythonBuild(\n",
    "            command=\"python demo.py\",\n",
    "            python_version=\"3.9\",\n",
    "            requirements_path=\"requirements.txt\"\n",
    "        ),\n",
    "    ),\n",
    "    env={\n",
    "        \"MODEL_DEPLOYED_URL\": MODEL_DEPLOYED_URL,\n",
    "    },\n",
    "    ports=[{\"port\": 8080, \"host\": \"churn-pred-demo.demo2.truefoundry.tech\"}], #In public cloud deployment TrueFoundry exposes port 8080\n",
    "    resources=Resources(\n",
    "        cpu_request=0.5, cpu_limit=0.5, memory_limit=2500, memory_request=1500\n",
    "    ),\n",
    "    replicas=1\n",
    ")\n",
    "service.deploy(workspace_fqn=WORKSPACE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcCdmKNKrA4X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "etyus4gpQXlJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda-jupyter-base",
   "language": "python",
   "name": "conda-env-.conda-jupyter-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
