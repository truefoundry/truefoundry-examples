{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4SfOLGlgkyJ"
      },
      "source": [
        "# Customer Churn Prediction with TrueFoundry\n",
        "\n",
        "\n",
        "Link to the problem statement: https://www.kaggle.com/c/customer-churn-prediction-2020\n",
        "\n",
        "This notebook contains a solution to the Customer Churn Prediction challenge by Kaggle. \n",
        "\n",
        "1. We use `GradientBoostingClassifier` for classification.\n",
        "2. We use `mlfoundry` to log metrics, datasets and model for each run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMYAgTMTuRRO"
      },
      "source": [
        "### Install and import Python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qRe2_hWgn9X",
        "outputId": "920f0075-ca96-43e2-fff6-a505fc90623a"
      },
      "outputs": [],
      "source": [
        "# install pip packages\n",
        "!pip install mlfoundry > /dev/null\n",
        "\n",
        "# import other things\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyE7CznGs-cD"
      },
      "source": [
        "### Copy MLFoundry API Key and save it against `api_token`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKDZ5It0yrz1",
        "outputId": "85e03869-c89b-4224-814c-f987dee58009"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "api_token = getpass(\"TrueFoundry API Token (Get it from https://app.truefoundry.com/settings):\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmshgBfUr_8G"
      },
      "source": [
        "### Create MLFoundty client\n",
        "\n",
        "We will use the client to log hyperparameters, metrics, datasets and logs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mw_sirvzbGy"
      },
      "outputs": [],
      "source": [
        "import mlfoundry as mlf\n",
        "mlf_client = mlf.get_client(api_key=api_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8MYN6AOiaMc",
        "outputId": "5677b493-ecf8-4dfa-c5fd-0a58709f761b"
      },
      "outputs": [],
      "source": [
        "# download the test and train datasets\n",
        "!curl -O https://raw.githubusercontent.com/truefoundry/truefoundry-examples/main/churn-prediction-sklearn/data/train.csv\n",
        "!curl -O https://raw.githubusercontent.com/truefoundry/truefoundry-examples/main/churn-prediction-sklearn/data/test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qMOxYzjVl3Q"
      },
      "source": [
        "### Let's create an MLFoundry run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXeUGGbdgGBc",
        "outputId": "9bd17867-841d-42d5-eb7f-5f0c2cb94294"
      },
      "outputs": [],
      "source": [
        "run = mlf_client.create_run(project_name=\"churn-prediction-sklearn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv9J7UKOseo9"
      },
      "source": [
        "### Load training data and split it into train and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "uqgX-4CSybHc",
        "outputId": "7541803e-405f-4739-e949-b9bdd8dd2d32"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48DzlR050hKZ",
        "outputId": "267eef77-e5ea-451a-84b9-4a18b359051e"
      },
      "outputs": [],
      "source": [
        "# divide the train dataset into test and train\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "X = df.drop(columns= ['churn'])\n",
        "y = df['churn']\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y , test_size=.25, stratify= y, random_state=1) \n",
        "\n",
        "# let's take a look at the value counts of yes and no\n",
        "y_train.value_counts(), y_val.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9cd2C2NzjOa"
      },
      "source": [
        "### Cleaning the data\n",
        "1. Calculate the `total_net_minutes` to reduce the number of features; do the same with calls, and charge\n",
        "2. Convert all `yes` and `no` strings into 0/1 in columns such as `voice_mail_plan`, `international_plan`, and `churn`\n",
        "3. Convert the categorical values such as `state` and `area_code` into one-hot vectors\n",
        "4. Drop all repeted features and unused columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIIlAvTp0Zok"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):    \n",
        "    df['total_net_minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']\n",
        "    df['total_net_calls'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']\n",
        "    df['total_net_charge'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']\n",
        "\n",
        "\n",
        "    df['voice_mail_plan'] = df['voice_mail_plan'].map({'yes': 1, 'no': 0}) \n",
        "    df['international_plan'] = df['international_plan'].map({'yes': 1, 'no': 0}) \n",
        "\n",
        "    df.drop(columns= ['state', 'area_code'], inplace= True)\n",
        "\n",
        "    df.drop(columns=['total_day_charge', 'total_eve_charge','total_night_charge',\n",
        "                    'total_day_calls','total_eve_calls', 'total_night_calls', 'total_day_minutes', \n",
        "                     'total_eve_minutes', 'total_night_minutes'], inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlEos7s_0zjF",
        "outputId": "ce0c3710-baa4-4e2a-b936-3ffd7d0d0d92"
      },
      "outputs": [],
      "source": [
        "x_train_clean  = clean_data(x_train)\n",
        "y_train_clean = pd.Categorical(y_train).codes\n",
        "\n",
        "x_val_clean = clean_data(x_val)\n",
        "y_val_clean = pd.Categorical(y_val).codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2dBE3MgtofS"
      },
      "source": [
        "### Log Dataset to MLFoundry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tt6gRXGjQUw",
        "outputId": "a87f78dc-6d98-4a55-9000-9c1c4ee8fde4"
      },
      "outputs": [],
      "source": [
        "run.log_dataset('train', features=x_train_clean, actuals=y_train_clean)\n",
        "run.log_dataset('validation', features=x_val_clean, actuals=y_val_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3piW2E9kuPmU"
      },
      "source": [
        "### Log our hyperparamters to MLFoundry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIwJCsSZ2Qds",
        "outputId": "724850fc-2a75-4d45-8670-0fca0cb5c78f"
      },
      "outputs": [],
      "source": [
        "LR = 0.05\n",
        "N_ESTIMATORS = 1000\n",
        "MAX_DEPTH = 10\n",
        "\n",
        "run.log_params({'learning_rate': LR, 'n_estimators': N_ESTIMATORS, 'max_depth': MAX_DEPTH})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZoUrL68udJ_"
      },
      "source": [
        "### Train XGBoost model on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9StyGcyiuJ_6"
      },
      "outputs": [],
      "source": [
        "xg = GradientBoostingClassifier(learning_rate=LR, n_estimators=N_ESTIMATORS,max_depth=MAX_DEPTH)\n",
        "xg.fit(x_train_clean, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIs-qugEufJt"
      },
      "source": [
        "### Log metrics\n",
        "\n",
        "We log the accuracy on training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL8dDUX53fTw"
      },
      "outputs": [],
      "source": [
        "run.log_metrics({'train_accuracy': xg.score(x_train_clean, y_train), 'val_accuracy': xg.score(x_val_clean, y_val)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cts0UNAjupF9"
      },
      "source": [
        "### Save the model with MLFoundry and end run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsRA9bCbi44l"
      },
      "outputs": [],
      "source": [
        "run.log_model(xg, 'sklearn')\n",
        "run.end()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "churn-prediction-tfy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
